{"nbformat_minor": 0, "cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Electron spline modelling"}, {"cell_type": "markdown", "metadata": {}, "source": "Write your desired energy and applicator in the cell immediately below then from the \"Cell\" menu above select \"Run All\""}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "energyRequest = 12\napplicatorRequest = '10x10'\nssdRequest = 110", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Input and output file locations"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "tag = '%dE_%sapp_%dSSD' %(energyRequest, applicatorRequest, ssdRequest)\n\npath2datafile = 'measured_output_factors.csv'\npath2outputfile = tag + '_report.html' ", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Modules"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "import plotly as py\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import pylab\n%matplotlib inline\n\nfrom scipy.interpolate import UnivariateSpline\nfrom scipy.interpolate import SmoothBivariateSpline\n\nfrom scipy.stats import shapiro, probplot, ttest_1samp\n\nfrom scipy.special import gamma\n\nfrom scipy.optimize import basinhopping\n\nimport plotly.plotly as py\nimport plotly.tools as tls\nfrom plotly.graph_objs import *\n\nimport os\n\nfrom io import BytesIO\nimport urllib\nimport base64\n\nfrom IPython.display import HTML, display\n\npylab.rcParams['savefig.dpi'] = 120", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Loading data"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "measuredRawData = pd.DataFrame.from_csv(path2datafile,index_col=False)\n\nphysicists = measuredRawData['Physicists'].values\ndate = measuredRawData['Date Measured'].values\n\nenergy = measuredRawData['Energy (MeV)'].values\napplicator = measuredRawData['Applicator (cm x cm)'].values\ninsert = measuredRawData['Insert (cm x cm)'].values\nshape = measuredRawData['Shape'].values\n\ncomment = measuredRawData['Comment'].values\nssd = measuredRawData['SSD (cm)'].values\n\ndetector = measuredRawData['Detector'].values\nrawOutputFactor = measuredRawData['Output Factor'].values\n\nuseFactor = measuredRawData['Use Factor (Y/N)'].values", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "outputFactor = np.zeros(np.shape(energy))\n\nfor i, outputFactorString in enumerate(rawOutputFactor):\n    \n    try:        \n        outputFactor[i] = np.float(outputFactorString)\n        \n    except:        \n        outputFactor[i] = np.nan", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "width = np.zeros(np.shape(energy))\nlength = np.zeros(np.shape(energy))\n\nfor i, insertString in enumerate(insert):\n    \n    dimenstionsString = insertString.split(\"x\")\n    \n    sideA = np.float(dimenstionsString[0])\n    sideB = np.float(dimenstionsString[1])\n    \n    if sideA < sideB:\n        width[i] = sideA\n        length[i] = sideB\n        \n    else:\n        \n        width[i] = sideB\n        length[i] = sideA\n        \n        \nratio = width/length\n\neqPonA = 2*( 3*(ratio+1) - np.sqrt( (3*ratio+1)*(ratio+3) ) ) / width", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "ref = (\n    (energy == energyRequest) & \n    (applicator == applicatorRequest) & \n    (ssd == ssdRequest) &\n    ((shape == 'Circle') | (shape == 'Oval')) &\n    (useFactor != 'N') &\n    ~np.isnan(outputFactor)\n)\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Sign into plotly and load/create site specific key"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "py.sign_in('SimonBiggs', 'oas177ahva')\n\nif (os.path.isfile('key.txt')):\n    \n    f = open('key.txt','r')\n    key = f.read()\n    f.close()\n\nelse:\n\n    key = \"%04d-%04d-%04d-%04d-%04d\" %tuple((np.floor(np.random.rand(5)*1e4)).astype(int))\n    \n    f = open('key.txt','w')\n    f.write(key)\n    f.close()", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Create the marker labels"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "marker_labels = [0,]*sum(ref)\n\nfor i in range(sum(ref)):\n    \n    marker_labels[i] = (\n        'Applicator: %s cm'\n        +'<br>Energy: %d MeV'\n        +'<br>SSD: %d cm'\n        +'<br>Width: %0.1f cm'\n        +'<br>Length: %0.1f cm'\n        +'<br>Output factor: %0.3f'\n        +'<br>Physicists: %s'\n        +'<br>Date: %s'\n        +'<br>Shape: %s'\n        +'<br>Detector: %s'\n        +'<br>Use Factor: %s'\n        \n    ) %(\n        applicator[ref][i],\n        energy[ref][i],\n        ssd[ref][i],\n        width[ref][i],\n        length[ref][i],\n        outputFactor[ref][i],\n        physicists[ref][i],\n        date[ref][i],\n        shape[ref][i],\n        detector[ref][i],\n        useFactor[ref][i]\n    )\n\n", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Create the width alone plot"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "plotScatter = Scatter(x=width[ref], y=outputFactor[ref], \n                      text=marker_labels,\n                      mode='markers', \n                      marker=Marker(size=15), \n                      name='Measured data')\n\ndataList = [plotScatter]\n\n\nxSpline = np.linspace(width[ref].min(),width[ref].max(),100)\nxSpline = np.unique(np.append(xSpline,width[ref]))\n\ntry:\n    spline1 = UnivariateSpline(width[ref],outputFactor[ref],k=1)\n    ySpline1 = spline1(xSpline)\n    plotSpline1 = Scatter(x=xSpline, y=ySpline1,\n                         line=Line(width=2,opacity=0.5), \n                         name='First order')\nexcept:\n    print(\"Cannot create first order fit\")\nelse:\n    dataList = dataList + [plotSpline1]\n\n\ntry:\n    spline2 = UnivariateSpline(width[ref],outputFactor[ref],k=2)\n    ySpline2 = spline2(xSpline)\n    plotSpline2 = Scatter(x=xSpline, y=ySpline2,\n                         line=Line(width=2,opacity=0.5), \n                         name='Second order')\nexcept:\n    print(\"Cannot create second order fit\")\nelse:\n    dataList = dataList + [plotSpline2]\n\n\n\ndata = Data(dataList)\n\nlayout = Layout(title=('Data plotted against width for lookup purposes'),\n                xaxis=XAxis(title='Width (cm)'),\n                yaxis=YAxis(title='Output factor'),\n                hovermode='closest')\n\nfig_width_input = Figure(data=data, layout=layout)\n\nfig_width = py.iplot(fig_width_input, \n         filename='%s_electron-fits_widthalone_' + tag)\n\nHTML(fig_width.embed_code)", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Create width and length fit"}, {"cell_type": "markdown", "metadata": {}, "source": "### Define threshold functions"}, {"cell_type": "markdown", "metadata": {}, "source": "#### Angle gap"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "def single_angle_gap(xTest,yTest,xData,yData,xScale,yScale):\n    \n    xi = xScale * (xData - xData.min()) / xData.ptp()\n    yi = yScale * (yData - yData.min()) / yData.ptp()\n    \n    xVal = xScale * (xTest - xData.min()) / xData.ptp()\n    yVal = yScale * (yTest - yData.min()) / yData.ptp()\n    \n    dx = xi - xVal\n    dy = yi - yVal\n    \n    if any((dx == 0) & (dy == 0)):\n        gap = 0\n        return gap\n        \n    theta = np.arctan(dy/dx)\n    theta[dx<0] = theta[dx<0] + np.pi\n    theta[(dx>0) & (dy<0)] = theta[(dx>0) & (dy<0)] + 2*np.pi\n    theta[(dx==0) & (dy>0)] = np.pi/2\n    theta[(dx==0) & (dy<0)] = 3*np.pi/2\n\n    test = np.sort(theta)\n    test = np.append(test,test[0] + 2*np.pi)\n    gap = np.max(np.diff(test))*180/np.pi\n\n    return gap\n\n\ndef angle_gap(xTest,yTest,xData,yData,xScale,yScale):\n    \n    dim = np.core.fromnumeric.shape(xTest)  \n    \n    if np.size(dim) == 0:\n        gap = single_angle_gap(xTest,yTest,xData,yData,xScale,yScale)\n        \n        return gap\n    \n    \n    gap = np.zeros(dim)\n    \n    \n    if np.size(dim) == 1:\n        for i in range(dim[0]):\n            gap[i] = single_angle_gap(xTest[i],yTest[i],xData,yData,xScale,yScale)\n            \n        return gap\n    \n    \n    for i in range(dim[0]):\n        for j in range (dim[1]):\n            gap[i,j] = single_angle_gap(xTest[i,j],yTest[i,j],xData,yData,xScale,yScale)\n\n    return gap", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "#### Fit give"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "def single_fit_give(xTest,yTest,xData,yData,zData,s=None,kx=2,ky=2):\n        \n    initialFitReturn = SmoothBivariateSpline(xData,yData,zData,kx=kx,ky=ky,s=s).ev(xTest,yTest)\n    \n    adjXData = np.append(xData,xTest)\n    adjYData = np.append(yData,yTest)\n    \n    posAdjZData = np.append(zData,initialFitReturn + 1)\n    negAdjZData = np.append(zData,initialFitReturn - 1)\n    \n    posFitReturn = SmoothBivariateSpline(adjXData,adjYData,posAdjZData,kx=kx,ky=ky,s=s).ev(xTest,yTest)\n    negFitReturn = SmoothBivariateSpline(adjXData,adjYData,negAdjZData,kx=kx,ky=ky,s=s).ev(xTest,yTest)\n    \n    posGive = posFitReturn - initialFitReturn\n    negGive = initialFitReturn - negFitReturn\n    \n    give = np.mean([posGive, negGive])\n    \n    return give\n\n\ndef fit_give(xTest,yTest,xData,yData,zData,s=None,kx=2,ky=2):\n    \n    dim = np.core.fromnumeric.shape(xTest)\n    \n    if np.size(dim) == 0:\n        give = single_fit_give(xTest,yTest,xData,yData,zData,s=s,kx=kx,ky=ky)\n        \n        return give\n    \n    \n    give = np.zeros(dim)\n    \n    \n    if np.size(dim) == 1:\n        for i in range(dim[0]):\n            give[i] = single_fit_give(xTest[i],yTest[i],xData,yData,zData,s=s,kx=kx,ky=ky)\n            \n        return give\n    \n    \n    for i in range(dim[0]):\n        for j in range (dim[1]):\n            give[i,j] = single_fit_give(xTest[i,j],yTest[i,j],xData,yData,zData,s=s,kx=kx,ky=ky)\n\n    return give", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Create the fit"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "numUniquePoints = len(np.unique(insert[ref]))\n\n\nif numUniquePoints < 6:\n    splinefail = True\n    splineOrder = 0\nelse:\n    splinefail = False\n\n\n\nif not(splinefail):\n    if numUniquePoints < 11:\n        kx = 1\n        ky = 1\n        splineOrder = 1\n\n    else:\n        kx = 2\n        ky = 2\n        splineOrder = 2\n    \n    bivariateSpline = SmoothBivariateSpline(width[ref],eqPonA[ref],outputFactor[ref],kx=kx,ky=ky)", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Calculate the mesh and find the threshold boundaries"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "minVal = np.floor(np.min(width[ref])*10)/10\nmaxVal = np.ceil(np.max(length[ref])*10)/10 + 0.1\n\nx = np.arange(minVal,maxVal,0.1)\ny = x.copy()\n\nxx, yy = np.meshgrid(x,y)\n\nif not(splinefail):\n    \n    mesh_width = xx.copy()\n    mesh_width[xx>yy] = yy[xx>yy]\n    \n    mesh_length = xx.copy()\n    mesh_length[yy>xx] = yy[yy>xx]\n    \n    mesh_ratio = mesh_width / mesh_length\n    \n    mesh_eqPonA = 2*( 3*(mesh_ratio+1) - np.sqrt( (3*mesh_ratio+1)*(mesh_ratio+3) ) ) / mesh_width\n       \n    zz = bivariateSpline.ev(mesh_width, mesh_eqPonA)\n    give = fit_give(mesh_width,mesh_eqPonA,width[ref],eqPonA[ref],outputFactor[ref],kx=kx,ky=ky)\n    gap = angle_gap(mesh_width,mesh_eqPonA,width[ref],eqPonA[ref],1,1)\n\n    outOfTolerance = (give > 0.5) | (gap > 180)\n\n    zz[outOfTolerance] = np.nan\n    \nelse:\n    \n    zz = np.empty(np.shape(xx))\n    zz[:] = np.nan\n    \nzz = np.floor(zz*1e4)/1e4", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n\n    c = plt.contourf(xx,yy,zz,100)\n    plt.colorbar(c)\n\n    plt.contour(xx,yy,give,levels=[0.5],colors='g')\n    plt.contour(xx,yy,gap,levels=[180],colors='r')\n\n    plt.scatter(width[ref],length[ref],s=30)\n    plt.scatter(length[ref],width[ref],s=30,alpha=0.2)\n\n    plt.xlabel('Width (cm)')\n    plt.ylabel('Length (cm)')\n    plt.title('Bivariate spline fit for %d MeV and %s cm applicator' %(energyRequest, applicatorRequest))\n\n    plt.axis('equal')", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "dtick = 0.02\n\ncolourWashMin = int(np.floor(np.min(outputFactor[ref])*100))/100\ncolourWashMax = int(np.ceil(np.max(outputFactor[ref])*100))/100\n\nnticks = int(np.floor((colourWashMax - colourWashMin)*100 + 1))\n\ntick0 = colourWashMin\n\nif not(splinefail):\n    measured1 = Scatter(x = width[ref],\n                        y = length[ref],\n                        text=marker_labels,\n                        mode='markers', \n                        marker=Marker(size=10),\n                        name='Measured data',\n                        xaxis='x1')\n\n    measured2 = Scatter(x = length[ref],\n                        y = width[ref],\n                        text=marker_labels,\n                        mode='markers', \n                        marker=Marker(size=10,opacity=0.3),\n                        name='Measured data',\n                        xaxis='x1')\n\n\n    colorbar = ColorBar(title='Output factor',\n                        titleside='right',\n                        autotick=False,\n                        nticks=nticks,\n                        dtick=dtick,\n                        tick0=tick0)\n\n\n    contour1 = Contour(z=zz,\n                       x=x,\n                       y=y,\n                       opacity=0.8,\n                       colorscale='YIGnBu',\n                       reversescale=True,\n                       ncontours='100',\n                       zauto=False,\n                       zmin=colourWashMin,\n                       zmax=colourWashMax,\n                       autocontour=True,\n                       contours=Contours(coloring='heatmap'),\n                       line=Line(width=0),\n                       name='Spline fit',\n                       xaxis='x1',\n                       colorbar=colorbar)\n\n\n    contour2 = Contour(z=zz,\n                       x=x,\n                       y=y,\n                       opacity=0.8,\n                       colorscale='YIGnBu',\n                       reversescale=True,\n                       ncontours='100',\n                       zauto=False,\n                       zmin=colourWashMin,\n                       zmax=colourWashMax,\n                       autocontour=True,\n                       contours=Contours(coloring='heatmap'),\n                       line=Line(width=0),\n                       name='Spline fit',\n                       xaxis='x2',\n                       colorbar=colorbar)\n\n    \n    \n    data = Data([measured1,measured2,contour1,contour2])\n\n    if splineOrder == 2:\n        \n        title = ('Bivariate quadratic spline fit using the parameters '\n                 '<i>equivalent width</i> and <i>equivalent perimeter on area</i>')\n        \n    elif splineOrder == 1:\n        \n        title = 'Plane fit using the parameters <i>equivalent width</i> and <i>equivalent perimeter on area</i>'\n    \n    \n    layout = Layout(xaxis1=XAxis(domain=[0,0.45],title='Width (cm)'),\n                    xaxis2=XAxis(domain=[0.55,1],title='Width (cm)'),\n                    yaxis=YAxis(title='Length (cm)'),\n                    title=title,\n                    hovermode='closest',               \n                    showlegend=False)\n\n\n    fig_widthlength_input = Figure(data=data, layout=layout)\n\n    fig_widthlength = py.iplot(fig_widthlength_input, \n             filename='%s_electron-fits_widthlength_' + tag)\n    \n    display(HTML(fig_widthlength.embed_code))", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Create the residuals histogram"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    \n    residuals_lengthwidth = outputFactor[ref] - bivariateSpline.ev(width[ref], eqPonA[ref])\n    \n    binSize = np.floor(4 * residuals_lengthwidth.ptp() / len(residuals_lengthwidth) / 0.0005) * 0.0005\n    binStart = np.floor(residuals_lengthwidth.min()/binSize)*binSize\n    binEnd = np.ceil(residuals_lengthwidth.max()/binSize)*binSize\n\n    bins = np.arange(binStart,binEnd+binSize,binSize)\n\n    \n    dbins = bins[1] - bins[0]\n    binsTrans = bins - dbins/2\n\n    binsTrans = binsTrans.reshape(-1,1)\n    binNum = np.argmin(abs(binsTrans - residuals_lengthwidth),0)\n\n    representative_height = np.zeros(len(binNum))\n\n    for i in range(len(bins)):\n\n        binRef = (binNum == i)\n\n        representative_height[binRef] = np.arange(sum(binRef)) + 1\n\n        \n    plt.hist(residuals_lengthwidth,bins,alpha=0.5)\n    plt.scatter(residuals_lengthwidth,representative_height,zorder=2,s=50,)", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    residualsScatter = Scatter(x=residuals_lengthwidth, \n                               y=representative_height, \n                               text=marker_labels,\n                               mode='markers', \n                               marker=Marker(size=15), \n                               name='Measured data')\n\n\n    residualsHistogram = Histogram(x=residuals_lengthwidth,\n                                   autobinx=False,\n                                   xbins=XBins(start=binStart,end=binEnd,size=binSize),\n                                   marker=Marker(color='rgb(165,231,255,0.5)',\n                                                 line=Line(color='black',width=2)),\n                                   name='Residuals histogram')\n\n\n    data = Data([residualsScatter,residualsHistogram])\n\n    layout = Layout(title='Histogram of residuals for identifying outliers',\n                    xaxis=XAxis(title=('Output factor residual error '\n                                       '(measured factor - fitted factor)'), zeroline=False),\n                    yaxis=YAxis(title='Frequency', zeroline=False),\n                    hovermode='closest',\n                    showlegend=False)\n\n    fig_residualsHist_input = Figure(data=data, layout=layout)\n\n    fig_residualsHist = py.iplot(fig_residualsHist_input, \n                    filename='%s_electron-fits_widthlength_residual_' + tag)\n    \n    display(HTML(fig_residualsHist.embed_code))", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Prediction percent difference"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "def c4(n):\n    \n    output = np.sqrt(2/(n-1)) * gamma(n/2) / gamma((n-1)/2)\n    if np.isnan(output):\n        output = 1\n        \n    return output", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    predictionValue = np.zeros(sum(ref))\n\n    for i in range(sum(ref)):\n\n        widthTest = np.delete(width[ref],i)\n        eqPonATest = np.delete(eqPonA[ref],i)\n        outputFactorTest = np.delete(outputFactor[ref],i)\n\n        predictionTestSpline = SmoothBivariateSpline(widthTest,eqPonATest,outputFactorTest,kx=kx,ky=ky)\n\n        predictionValue[i] = predictionTestSpline.ev(width[ref][i],eqPonA[ref][i])\n        \n\n    predictionDifference = outputFactor[ref] - predictionValue\n\n    plt.hist(predictionDifference,alpha=0.5)\n\n    predictionStd = np.std(predictionDifference,ddof=1) / c4(len(predictionDifference))\n\n    print(predictionStd)\n    print(np.mean(predictionDifference))", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    \n    percentDifference = 100*(outputFactor[ref] - predictionValue)/outputFactor[ref]\n       \n    binSize = np.floor(4 * percentDifference.ptp() / len(percentDifference) / 0.05) * 0.05\n    binStart = np.floor(percentDifference.min()/binSize)*binSize\n    binEnd = np.ceil(percentDifference.max()/binSize)*binSize\n\n    bins = np.arange(binStart,binEnd+binSize,binSize)\n\n    \n    dbins = bins[1] - bins[0]\n    binsTrans = bins - dbins/2\n\n    binsTrans = binsTrans.reshape(-1,1)\n    binNum = np.argmin(abs(binsTrans - percentDifference),0)\n\n    representative_height = np.zeros(len(binNum))\n\n    for i in range(len(bins)):\n\n        binRef = (binNum == i)\n\n        representative_height[binRef] = np.arange(sum(binRef)) + 1\n\n        \n    plt.hist(percentDifference,bins,alpha=0.5)\n    plt.scatter(percentDifference,representative_height,zorder=2,s=50,)", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    residualsScatter = Scatter(x=percentDifference, \n                               y=representative_height, \n                               text=marker_labels,\n                               mode='markers', \n                               marker=Marker(size=15), \n                               name='Measured data')\n\n\n    residualsHistogram = Histogram(x=percentDifference,\n                                   autobinx=False,\n                                   xbins=XBins(start=binStart,end=binEnd,size=binSize),\n                                   marker=Marker(color='rgb(165,231,255,0.5)',\n                                                 line=Line(color='black',width=2)),\n                                   name='Percent difference')\n\n    # residualsHistogram = Histogram(x=residuals_lengthwidth)\n\n\n    data = Data([residualsScatter,residualsHistogram])\n\n    layout = Layout(title='Distribution of percent difference between measured and predicted factors',\n                    xaxis=XAxis(title=('Percent difference &emsp; '\n                                       '[  100 &times; ( measured - predicted ) / measured  ]'), zeroline=False),\n                    yaxis=YAxis(title='Frequency', zeroline=False),\n                    hovermode='closest',\n                    showlegend=False)\n\n    fig_predictionDiffHist_input = Figure(data=data, layout=layout)\n\n    fig_predictionDiffHist = py.iplot(fig_predictionDiffHist_input, \n                    filename='%s_electron-fits_widthlength_predictionDiff_' + tag)\n    \n    display(HTML(fig_predictionDiffHist.embed_code))", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Calculating Stats"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    t, ttestProb = ttest_1samp(percentDifference,0)\n    res_ttest = \"%0.4f\" %(ttestProb)\n    \n    if ttestProb < 0.1:\n        tSignificance = 'significant'\n    else:\n        tSignificance = 'not significant'\n        \n    print('t-Test: ' + res_ttest + ' which is ' + tSignificance)\n    \n    W, shapiroProb = shapiro(percentDifference)\n    res_norm = \"%0.4f\" %(shapiroProb)\n    \n    if shapiroProb < 0.1:\n        shSignificance = 'significant'\n    else:\n        shSignificance = 'not significant'\n    \n    print('Shapiro: ' + res_norm + ' which is ' + shSignificance)\n    \n      \n    \n    residualStd = np.std(percentDifference,ddof=1) / c4(len(percentDifference))\n    \n    res_std = \"%0.2f\" %(residualStd)\n    print('Standard deviation with bias correction: ' + res_std)\n    \n    res_mean = \"%0.2f\" %(np.mean(percentDifference))\n    print('Mean:' + res_mean)", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    fig = plt.figure(figsize=(7,4))\n    ax = fig.add_subplot(111)\n\n    probplot(percentDifference, plot=ax);\n\n    ax.set_title(\"Normality probability plot for the percent differences\")\n\n    figData = BytesIO()\n    pylab.savefig(figData)\n    \n    figData.seek(0)\n    figString = urllib.parse.quote(base64.b64encode(figData.getvalue()))\n    probplotImageEmbed = '<img alt=\"Embedded Image\" src=\"data:image/png;base64,'+figString+'\" />'", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Estimated uncertainties"}, {"cell_type": "markdown", "metadata": {}, "source": "### Estimated variable uncertainties via smooth bootstrapping"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    predictions = bivariateSpline.ev(width[ref], eqPonA[ref])\n\n    numTrials = 5000\n\n    resampleSpline = [0,]*numTrials\n    resampledPredictions = np.zeros(np.shape(mesh_width) + (numTrials,))\n\n    for i in range(numTrials):\n\n        resample = np.random.normal(loc=predictions, scale=predictionStd)\n        resampleSpline[i] = SmoothBivariateSpline(width[ref],eqPonA[ref],resample,kx=kx,ky=ky)\n\n        resampledPredictions[:,:,i] = resampleSpline[i].ev(mesh_width, mesh_eqPonA)\n    ", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    variableUncertaintyEstimate = np.std(resampledPredictions,ddof=1,axis=2) / c4(numTrials)\n\n    variableUncertaintyEstimate[outOfTolerance] = np.nan\n\n    c = plt.contourf(xx,yy,variableUncertaintyEstimate,100)\n    plt.colorbar(c)\n\n    plt.contour(xx,yy,give,levels=[0.5],colors='g')\n    plt.contour(xx,yy,gap,levels=[180],colors='r')\n\n    plt.scatter(width[ref],length[ref],s=30)\n    plt.scatter(length[ref],width[ref],s=30,alpha=0.2)", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Estimate constant uncertainty"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "class constant_uncertainty(object):\n    \"\"\"Find the constant uncertainty throughout the fit.\n    \"\"\"\n    def __init__(self, n=5, debug=False, **kwargs):\n        \n        self.debug=debug\n        \n        self.residuals = kwargs['residuals']\n        self.variableUncertainty = kwargs['variableUncertainty']\n\n                \n        self.basinRequiredSuccess = n\n        self.constantUncertainty = np.abs(self.uncertainty_basinhopping())\n        \n        self.totalUncertainty = np.sqrt(self.variableUncertainty**2 + \n                                        self.constantUncertainty**2)\n        \n\n    def c4(n):\n    \n        output = np.sqrt(2/(n-1)) * gamma(n/2) / gamma((n-1)/2)\n        if np.isnan(output):\n            output = 1\n\n        return output\n    \n    \n    def minimise_function(self, constantUncertaintyGuess):\n\n        totalUncertaintyGuess = np.sqrt(self.variableUncertainty**2 + constantUncertaintyGuess**2)\n\n        scaled = self.residuals / totalUncertaintyGuess\n\n        scaledStd = np.std(scaled,ddof=1) / c4(len(scaled))\n        \n        return (scaledStd - 1)**2\n        \n    \n    def uncertainty_basinhopping(self):\n\n        self.functionReturns = np.empty(self.basinRequiredSuccess)\n        self.functionReturns[:] = np.nan\n        \n        self.numSuccess = 0\n        \n        minimizerConfig = {\"method\": 'BFGS'}\n        \n        initial_input = np.array([0.01])\n        \n        \n        basinhoppingOutput = basinhopping(self.minimise_function,\n                                          initial_input,\n                                          niter=1000,\n                                          minimizer_kwargs=minimizerConfig,\n                                          take_step=self.step_function,\n                                          callback=self.callback_function)\n        \n        return basinhoppingOutput.x\n        \n        \n    def step_function(self,optimiserInput):\n\n        optimiserInput[0] += np.random.normal(scale=0.01)   # x-position\n        \n        return optimiserInput\n    \n    \n    def callback_function(self, optimiserOutput, minimiseFunctionOutput, minimiseAccepted):\n       \n        if self.debug:\n            print(optimiserOutput)\n            print(minimiseFunctionOutput)\n            print(minimiseAccepted)\n            print(\" \")\n        \n        if minimiseAccepted:\n            \n            if self.numSuccess == 0:\n                # First result\n                self.functionReturns[0] = minimiseFunctionOutput\n                self.numSuccess = 1\n                \n            elif minimiseFunctionOutput >= np.nanmin(self.functionReturns) + 0.0001:\n                # Reject result\n                0\n                \n            elif minimiseFunctionOutput >= np.nanmin(self.functionReturns) - 0.0001:\n                # Agreeing result\n                self.functionReturns[self.numSuccess] = minimiseFunctionOutput\n                self.numSuccess += 1\n            \n            elif minimiseFunctionOutput < np.nanmin(self.functionReturns) - 0.0001:\n                # New result\n                self.functionReturns[0] = minimiseFunctionOutput\n                self.numSuccess = 1\n        \n        if self.numSuccess >= self.basinRequiredSuccess:\n            return True\n        ", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    resampledPredictionsAtPoints = np.zeros(np.shape(width[ref]) + (numTrials,))\n\n    for i in range(numTrials):\n\n        resampledPredictionsAtPoints[:,i] = resampleSpline[i].ev(width[ref],eqPonA[ref])\n\n    fittingUncertainty = np.std(resampledPredictionsAtPoints,ddof=1,axis=1) / c4(numTrials)\n    # fittingUncertainty\n\n    measuredUncertaintyEstimate = constant_uncertainty(residuals=predictionDifference, \n                                                       variableUncertainty=fittingUncertainty)\n\n    measuredUncertaintyEstimate.constantUncertainty\n\n    measuredUncertaintyString = '%0.2f%%' %(measuredUncertaintyEstimate.constantUncertainty*100)\n    print(measuredUncertaintyString)", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "### Estimated total uncertainty"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n\n    totalUncertaintyEstimate = np.sqrt(variableUncertaintyEstimate**2 + \n                                       measuredUncertaintyEstimate.constantUncertainty**2)\n    \n    totalUncertaintyEstimate = np.around(totalUncertaintyEstimate,decimals=5)\n    \n    c = plt.contourf(xx,yy,totalUncertaintyEstimate,200)\n    plt.colorbar(c)\n\n    plt.contour(xx,yy,give,levels=[0.5],colors='g')\n    plt.contour(xx,yy,gap,levels=[180],colors='r')\n\n    plt.scatter(width[ref],length[ref],s=30)\n    plt.scatter(length[ref],width[ref],s=30,alpha=0.2)", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "if not(splinefail):\n    measured1 = Scatter(x = width[ref],\n                        y = length[ref],\n                        text=marker_labels,\n                        mode='markers', \n                        marker=Marker(size=10),\n                        name='Measured data',\n                        xaxis='x1')\n\n    measured2 = Scatter(x = length[ref],\n                        y = width[ref],\n                        text=marker_labels,\n                        mode='markers', \n                        marker=Marker(size=10,opacity=0.3),\n                        name='Measured data',\n                        xaxis='x1')\n\n\n    colorbar = ColorBar(title='Estimated uncertainty',\n                        titleside='right')\n\n\n    contour1 = Contour(z=totalUncertaintyEstimate,\n                       x=x,\n                       y=y,\n                       opacity=0.8,\n                       colorscale='YIOrRd',\n                       reversescale=True,\n                       ncontours='100',\n                       autocontour=True,\n                       contours=Contours(coloring='heatmap'),\n                       line=Line(width=0),\n                       name='Estimated uncertainty',\n                       xaxis='x1',\n                       colorbar=colorbar)\n\n\n    contour2 = Contour(z=totalUncertaintyEstimate,\n                       x=x,\n                       y=y,\n                       opacity=0.8,\n                       colorscale='YIOrRd',\n                       reversescale=True,\n                       ncontours='100',\n                       autocontour=True,\n                       contours=Contours(coloring='heatmap'),\n                       line=Line(width=0),\n                       name='Estimated uncertainty',\n                       xaxis='x2',\n                       colorbar=colorbar)\n\n    \n    \n    data = Data([measured1,measured2,contour1,contour2])\n\n    layout = Layout(xaxis1=XAxis(domain=[0,0.45],title='Width (cm)'),\n                    xaxis2=XAxis(domain=[0.55,1],title='Width (cm)'),\n                    yaxis=YAxis(title='Length (cm)'),\n                    title='Estimated uncertainty for the prediction of a measured Output factor',\n                    hovermode='closest',               \n                    showlegend=False)\n\n\n    fig_uncertainty_input = Figure(data=data, layout=layout)\n\n    fig_uncertainty = py.iplot(fig_uncertainty_input, \n             filename='%s_electron-fits_uncertainty_' + tag)\n    \n    display(HTML(fig_uncertainty.embed_code))", "outputs": []}, {"cell_type": "markdown", "metadata": {}, "source": "## Save a summary"}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "# Spline explaination\nsplineExplain = ('You currently have <b>%d unique widths '\n                 'and lengths</b> in this set, therefore a ') %(numUniquePoints) \n\nif splineOrder == 1:\n    splineExplain += '''<b>first order spline (aka a plane)</b> has been used to fit your data. \n                        A better fit would be achievable if you use at least eleven data points.'''\nelif splineOrder == 2:\n    splineExplain += ('<b>second order bivariate spline (aka quadratic bivariate spline)'\n                      '</b> has been used to fit your data.')\n    \nelse:\n    splineExplain += '''a spline fit was unavailable for your data set. Please collect \n        at least six data points to use a plane to fit your data, or eleven data points \n        so that a quadratic spline can be used.'''\n    \n\nif not(splinefail):\n    \n    uncertaintyExplain = ('This fit has an estimated uncertainty in prediction of <b>&plusmn;' \n                          + res_std + ' %</b>.')", "outputs": []}, {"cell_type": "code", "metadata": {"collapsed": false, "trusted": false}, "execution_count": null, "source": "html_string = '''\n<!DOCTYPE html>\n<html>\n    <head>\n        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n        <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css\">\n        <style>\n        \n            body { \n                \n                background:whitesmoke;\n                width: 80%;\n                margin: 60px auto;\n            }\n            \n            section.left {\n                width:65%;\n                float:left;\n            }\n            \n            section {\n                padding:20px;\n            \n            }\n            \n            aside {\n                padding:20px;\n            \n            }\n            \n            td {\n                padding:20px;            \n            }\n            \n        </style>\n    </head>\n    <body>\n        \n        <section>\n        <h1>Electron equivalent ellipse spline modelling</h1>\n        </section>\n        \n        <section>\n        <h2>Energy: ''' + str(energyRequest) + ''' MeV &emsp;&emsp;\n        Applicator: ''' + str(applicatorRequest) + ''' cm &emsp;&emsp;\n        SSD: ''' + str(ssdRequest) + ''' cm &emsp;&emsp;\n        <i>Include reference conditions here</i></h2>\n        </section>\n        \n\n        '''\n    \n\nif not(splinefail):\n\n    html_string += '''\n            \n            <section class=\"left\">\n            <h3>Bivariate spline fit for interpolation purposes</h3>\n            \n            <p>''' + splineExplain + ' ' + uncertaintyExplain+'''</p>\n            \n            <p>Below is the fit formed using the parameters <i>equivalent width</i> and \n            <i>equivalent perimeter on area</i>.\n            For ease of use the results are plotted with respect to <i>length</i> and <i>width</i>. \n            The valid fitting region is given as a colourwash. \n            The colour of the colourwash is representative of the fitted output factor.</p>\n            \n            <p>Hovering your mouse over the righthand plot will give the output factor results in the \n            <i>z</i> parameter.\n            Where the <i>z</i> paramater returns null, and there is no colour wash, \n            is not a valid fitting region. This may be due either to not having enough points \n            in the direct vicinity, or the region being outside the external data \n            boundary.</p>\n            \n            <p>Hovering your mouse over the lefthand plot will provide you with a way \n            to lookup individual measured data points.\n            Your measured data is given in blue. \n            The equivalent shape with <i>width</i> and <i>length</i> inverted is given in orange.</p>\n            \n            </section>\n            \n            <aside><i>Diagram of length and width using an ellipse goes here... \n            maybe have a semi irregular cutout and an equivalent ellipse overlay to \n            represent length and width</i></aside>\n            \n            <section>''' + fig_widthlength.embed_code + '''</section>\n            \n            <section class=\"left\">\n                <h3>Estimated total standard uncertainty in predicting a measured output factor</h3>\n                <p>The following is an estimate of total standard uncertainty \n                for the prediction of a measured output factor.\n                It takes into account variations in uncertainty about the fit via Smooth Bootstrapping.\n                This is based upon an approximate measurement uncertainty of \n                ''' + measuredUncertaintyString + '''.</p>\n            </section>\n            \n            <section>''' + fig_uncertainty.embed_code + '''</section>\n            \n            \n            <section class=\"left\">\n                <h3>Distribution of the percent difference between measured and predicted factors</h3>\n                <p>In order to determine the uncertainty for prediction each \n                data point in turn is removed from the fit\n                and then the model attenmpts to predict the just removed point. \n                This prediction is then compared with\n                the measured factor.</p>\n                \n                <p>Below is the distribution of percent differences between the \n                measured factors and these factor predictions\n                calculated after removal. This is calculated as \n                %diff = 100 &times; ( measured - predicted ) / measured.</p>\n                \n                <p>It is expected that points on the edge of the fitting region would become outliers\n                in this distribution due to forcing extrapolation upon the model.</p>\n            \n            </section>\n            \n            <section>''' + fig_predictionDiffHist.embed_code + '''</section>\n            \n            <section class=\"left\">\n                <h3>Prediction percent difference statistics</h3>\n                \n                <p>The percent difference <b>mean is ''' + res_mean + ''' %</b>, which is \n                ''' + tSignificance + ''' with a <b>p-value of '''+ res_ttest +'''</b>.</p>\n                <p>The <b>standard deviation</b> corrected for bias using an assumtion of a normality is \n                <b>&plusmn;''' + res_std + ''' %</b>.</p>\n                <p>The <b>p-value</b> for the Shapiro test for <b>normality is ''' + res_norm + '''</b>.</p>\n                \n                <p>A normality probability plot is given below to further investigate the \n                normality of the percent difference distribtion.</p>\n                \n            </section>\n            \n            <section>'''+probplotImageEmbed+'''</section>\n            \n            \n            \n            <section class=\"left\">\n                <h3>Identifying outliers via the residuals histogram</h3>\n                <p>A histogram of the residual error between the modelled factors \n                (without removal) and the measured factors\n                is given below. Its primary use is for the identification of outliers \n                in your measurement data.</p>\n             </section>\n             \n             <section>'''+ fig_residualsHist.embed_code + '''</section>\n            \n            \n\n    '''\n    \nelse:\n    \n    html_string += '''\n        <section>\n            <h3>Bivariate spline fit for interpolation purposes unavailable</h3>\n            <p>''' + splineExplain + '''</p>\n        <section>\n                '''\n    \nhtml_string += '''\n        \n        <section class=\"left\">\n        <h3>Width alone fits for lookup purposes</h3>\n            <p>The univariate fits provided in the figure just below are intented to be used \n            as a guide for lookup purposes.</p>\n        </section>\n        \n        <section>''' + fig_width.embed_code + '''</section>\n    \n    </body>\n</html>'''\n\nf = open(path2outputfile,'w')\nf.write(html_string)\nf.close()", "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"version": "3.4.0", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4}